{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(z):\n",
    "     return np.c_[z.mean(axis=1),\n",
    "                  np.median(np.abs(z), axis=1),\n",
    "                  z.std(axis=1),\n",
    "                  z.max(axis=1),\n",
    "                  z.min(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_X(data):\n",
    "    for i, x in enumerate(data):\n",
    "        print(\"chunk num: %s\"%(i) + \"\\r\")\n",
    "        temp = (x-5)/3#hypotest?Z\n",
    "        features = extract_features(temp)\n",
    "        print(\"mean: %s\"%features[0])\n",
    "        print(\"median: %s\"%features[1])\n",
    "        print(\"std: %s\"%features[2])\n",
    "        print(\"max: %s\"%features[3])\n",
    "        print(\"min: %s\"%features[4])\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(x, last_index=None, n_steps=150, step_length=1000):\n",
    "    if last_index == None:\n",
    "        last_index=len(x)\n",
    "    #print(last_index)\n",
    "    #print(n_steps * step_length)\n",
    "    assert last_index - n_steps * step_length >= 0\n",
    "\n",
    "    # Reshaping and approximate standardization with mean 5 and std 3.\n",
    "    #[:]\n",
    "    #why 5, 3?\n",
    "    temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1) - 5 ) / 3\n",
    "    #temp = (x[(last_index - n_steps * step_length):(n_steps * step_length)].reshape(n_steps, -1) - 5 ) / 3\n",
    "    # Extracts features of sequences of full length 1000, of the last 100 values and finally also\n",
    "    # of the last 10 observations.\n",
    "    return np.c_[extract_features(temp),\n",
    "                 extract_features(temp[:, -step_length // 10:]),\n",
    "                 extract_features(temp[:, -step_length // 100:]),\n",
    "                 temp[:, -1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(file_path, n_features=16, batch_limit=10, batch_size=16, n_steps=150, step_length = 1000):\n",
    "    epoch = 0\n",
    "    chunksize = n_steps*step_length\n",
    "    while True:\n",
    "        for i in range(batch_limit*2):\n",
    "            float_data1 = pd.read_csv(f\"{file_path}{i}.csv\",\n",
    "                dtype={\"acoustic_data\": np.float32, \"time_to_failure\": np.float32})\n",
    "            float_data2 = pd.read_csv(f\"{file_path}{i+1}.csv\",\n",
    "                dtype={\"acoustic_data\": np.float32, \"time_to_failure\": np.float32})\n",
    "            data = np.vstack((float_data1.values, float_data2.values))\n",
    "            rows = np.random.randint(chunksize, size=batch_size)\n",
    "            samples = np.zeros((batch_size, n_steps, n_features))\n",
    "            targets = np.zeros(batch_size, )\n",
    "            sample_ranges = None\n",
    "            for j, row in enumerate(rows):\n",
    "                samples[j] = create_X(data[:, 0], last_index=None, n_steps=n_steps, step_length=step_length)\n",
    "                targets[j] = data[row, 1]\n",
    "                sample_range = np.arange(i*chunksize+row-chunksize, i*chunksize+row)\n",
    "                if sample_ranges is None:\n",
    "                    sample_ranges = sample_range\n",
    "                else:\n",
    "                    sample_ranges = np.vstack((sample_ranges, sample_range))\n",
    "            yield samples, targets, sample_ranges, epoch\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(file_path, n_features=16, batch_limit=10, batch_size=16, n_steps=150, step_length = 1000):\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        chunksize = 2*n_steps*step_length\n",
    "        float_data = pd.read_csv(f\"input/{file_path}\", chunksize=chunksize,\n",
    "            dtype={\"acoustic_data\": np.float32, \"time_to_failure\": np.float32})\n",
    "        for i, data in enumerate(float_data):\n",
    "            if i == batch_limit:\n",
    "                epoch += 1\n",
    "                break\n",
    "            #if i == len(float_data):\n",
    "            #if data.shape[0] != chunksize:\n",
    "                #idk end edge case\n",
    "            #    epoch += 1\n",
    "            #    continue\n",
    "            data = data.values\n",
    "            rows = np.random.randint(n_steps*step_length, chunksize, size=batch_size)#makes cv here?\n",
    "            samples = np.zeros((batch_size, n_steps, n_features))\n",
    "            targets = np.zeros(batch_size, )\n",
    "            sample_ranges = None\n",
    "            for j, row in enumerate(rows):\n",
    "                #try:\n",
    "                #print(\"row: %s\"%row)\n",
    "                samples[j] = create_X(data[:, 0], last_index=row, n_steps=n_steps, step_length=step_length)\n",
    "                #except TypeError:\n",
    "                #    print(data.shape)\n",
    "                targets[j] = data[row, 1]\n",
    "                sample_range = np.arange(i*chunksize+row-chunksize, i*chunksize+row)\n",
    "                if sample_ranges is None:\n",
    "                    sample_ranges = sample_range\n",
    "                else:\n",
    "                    sample_ranges = np.vstack((sample_ranges, sample_range))\n",
    "\n",
    "            np.expand_dims(targets, 1)\n",
    "            \n",
    "            sample_range = np.arange(i*chunksize, i*chunksize)#or might be 2d with shape(chunksize, batch_size)\n",
    "            yield samples, targets, sample_ranges, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
