{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(z):\n",
    "     return np.c_[z.mean(axis=1),\n",
    "                  np.median(np.abs(z), axis=1),\n",
    "                  z.std(axis=1),\n",
    "                  z.max(axis=1),\n",
    "                  z.min(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_X(data):\n",
    "    for i, x in enumerate(data):\n",
    "        print(\"chunk num: %s\"%(i) + \"\\r\")\n",
    "        temp = (x-5)/3#hypotest?Z\n",
    "        features = extract_features(temp)\n",
    "        print(\"mean: %s\"%features[0])\n",
    "        print(\"median: %s\"%features[1])\n",
    "        print(\"std: %s\"%features[2])\n",
    "        print(\"max: %s\"%features[3])\n",
    "        print(\"min: %s\"%features[4])\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(x, last_index=None, n_steps=150, step_length=1000):\n",
    "    if last_index == None:\n",
    "        last_index=len(x)\n",
    "    #print(last_index)\n",
    "    #print(n_steps * step_length)\n",
    "    assert last_index - n_steps * step_length >= 0\n",
    "\n",
    "    # Reshaping and approximate standardization with mean 5 and std 3.\n",
    "    #[:]\n",
    "    #why 5, 3?\n",
    "    temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1) - 5 ) / 3\n",
    "    #temp = (x[(last_index - n_steps * step_length):(n_steps * step_length)].reshape(n_steps, -1) - 5 ) / 3\n",
    "    # Extracts features of sequences of full length 1000, of the last 100 values and finally also\n",
    "    # of the last 10 observations.\n",
    "    return np.c_[extract_features(temp),\n",
    "                 extract_features(temp[:, -step_length // 10:]),\n",
    "                 extract_features(temp[:, -step_length // 100:]),\n",
    "                 temp[:, -1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 16\n",
    "\n",
    "BATCH_LIMIT = 40 #up to 4196/2, factor of 2 in batch_generator\n",
    "TRAIN_FILEPATH = \"input/train/train_batch_num\"\n",
    "#also try train_batch_num implementation\n",
    "#since certain ranges not considered, limited by chunksize chunking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(file_name, batch_size=16, n_steps=150, step_length = 1000):\n",
    "    epoch = 0\n",
    "    chunksize = n_steps*step_length\n",
    "    while True:\n",
    "        for i in range(BATCH_LIMIT*2):\n",
    "            float_data1 = pd.read_csv(f\"{TRAIN_FILEPATH}{i}.csv\",\n",
    "                dtype={\"acoustic_data\": np.float32, \"time_to_failure\": np.float32})\n",
    "            float_data2 = pd.read_csv(f\"{TRAIN_FILEPATH}{i+1}.csv\",\n",
    "                dtype={\"acoustic_data\": np.float32, \"time_to_failure\": np.float32})\n",
    "            data = np.vstack((float_data1.values, float_data2.values))\n",
    "            rows = np.random.randint(chunksize, size=batch_size)\n",
    "            samples = np.zeros((batch_size, n_steps, n_features))\n",
    "            targets = np.zeros(batch_size, )\n",
    "            sample_ranges = None\n",
    "            for j, row in enumerate(rows):\n",
    "                samples[j] = create_X(data[:, 0], last_index=None, n_steps=n_steps, step_length=step_length)\n",
    "                targets[j] = data[row, 1]\n",
    "                sample_range = np.arange(i*chunksize+row-chunksize, i*chunksize+row)\n",
    "                if sample_ranges is None:\n",
    "                    sample_ranges = sample_range\n",
    "                else:\n",
    "                    sample_ranges = np.vstack((sample_ranges, sample_range))\n",
    "            yield samples, targets, sample_ranges, epoch\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(file_path, batch_size=16, n_steps=150, step_length = 1000):\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        chunksize = 2*n_steps*step_length\n",
    "        float_data = pd.read_csv(f\"input/{file_path}\", chunksize=chunksize,\n",
    "            dtype={\"acoustic_data\": np.float32, \"time_to_failure\": np.float32})\n",
    "        for i, data in enumerate(float_data):\n",
    "            if i == BATCH_LIMIT:\n",
    "                epoch += 1\n",
    "                break\n",
    "            #if i == len(float_data):\n",
    "            #if data.shape[0] != chunksize:\n",
    "                #idk end edge case\n",
    "            #    epoch += 1\n",
    "            #    continue\n",
    "            data = data.values\n",
    "            rows = np.random.randint(n_steps*step_length, chunksize, size=batch_size)#makes cv here?\n",
    "            samples = np.zeros((batch_size, n_steps, n_features))\n",
    "            targets = np.zeros(batch_size, )\n",
    "            sample_ranges = None\n",
    "            for j, row in enumerate(rows):\n",
    "                #try:\n",
    "                #print(\"row: %s\"%row)\n",
    "                samples[j] = create_X(data[:, 0], last_index=row, n_steps=n_steps, step_length=step_length)\n",
    "                #except TypeError:\n",
    "                #    print(data.shape)\n",
    "                targets[j] = data[row, 1]\n",
    "                sample_range = np.arange(i*chunksize+row-chunksize, i*chunksize+row)\n",
    "                if sample_ranges is None:\n",
    "                    sample_ranges = sample_range\n",
    "                else:\n",
    "                    sample_ranges = np.vstack((sample_ranges, sample_range))\n",
    "\n",
    "            np.expand_dims(targets, 1)\n",
    "            \n",
    "            sample_range = np.arange(i*chunksize, i*chunksize)#or might be 2d with shape(chunksize, batch_size)\n",
    "            yield samples, targets, sample_ranges, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nbformat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mget_cells\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2761\u001b[0m             \u001b[0;34m\"\"\"generator for sequence of code blocks to run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.ipynb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2763\u001b[0;31m                 \u001b[0;32mfrom\u001b[0m \u001b[0mnbformat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2764\u001b[0m                 \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nbformat'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT IS I: 0\n",
      "(32, 150, 16)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "%run quakedatagen.ipynb\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "float_data_file_path = \"train.csv\"\n",
    "#train_gen = generator(float_data_file_path, batch_size=batch_size)\n",
    "#valid_gen = generator(float_data_file_path, batch_size=batch_size)\n",
    "train_gen = batch_generator(float_data_file_path, batch_size=batch_size)\n",
    "valid_gen = batch_generator(float_data_file_path, batch_size=batch_size)\n",
    "\n",
    "for i, batch in enumerate(train_gen):\n",
    "    print(\"IT IS I: %s\"%i)\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, CuDNNGRU, RNN, SimpleRNNCell, Flatten, SimpleRNN, Conv1D\n",
    "from keras.optimizers import adam\n",
    "from keras.callbacks import ModelCheckpoint, BaseLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 300       # number of times the model sees all the data during training\n",
    "\n",
    "N_FORWARD = 8       # train the network to predict N in advance (traditionally 1)\n",
    "#RESAMPLE_BY = 5     # averaging period in days (training on daily data is too much)\n",
    "RNN_CELLSIZE = 48  # size of the RNN cells\n",
    "LSTM_CELLSIZE = 32 # size of the LSTM cells\n",
    "N_LAYERS = 6        # number of stacked RNN cells (needed for tensor shapes but code must be changed manually)\n",
    "SEQLEN = 32        # unrolled sequence length\n",
    "BATCHSIZE = 32      # mini-batch size\n",
    "DROPOUT_PKEEP = 0.7 # probability of neurons not being dropped (should be between 0.5 and 1)\n",
    "ACTIVATION = tf.nn.tanh # Activation function for GRU cells (tf.nn.relu or tf.nn.tanh)\n",
    "\n",
    "JOB_DIR  = \"checkpoints\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm_fn(features, Hin, labels, step, dropout_pkeep):\n",
    "    X = features  # shape [BATCHSIZE, SEQLEN, 2], 2 for (agg_features)\n",
    "    batchsize = tf.shape(X)[0]\n",
    "    seqlen = tf.shape(X)[1]\n",
    "    pairlen = tf.shape(X)[2] # should be 2 (acoustic_data, time_to_failure)?\n",
    "\n",
    "    cells = [tf.contrib.rnn.GRUBlockCell(LSTM_CELLSIZE, activation=ACTIVATION) for _ in range(N_LAYERS)]\n",
    "    # dropout useful between cell layers only: no output dropout on last cell-is this good with LSTM? probably\n",
    "    cells = [tf.contrib.rnn.lstm_cell.DropoutWrapper(cell, output_keep_prob = dropout_pkeep) for cell in cells]\n",
    "    # a stacked LSTM cell still works like an LSTM cell???\n",
    "    cell = tf.contrib.rnn.lstm_cell.MultiLSTMCell(cells, state_is_tuple=False)\n",
    "    # X[BATCHSIZE, SEQLEN, 2], Hin[BATCHSIZE, LSTM_CELLSIZE*N_LAYERS]\n",
    "    # the sequence unrolling happens here\n",
    "    Yn, H = tf.contrib.rnn.dynamic_lstm(cell, X, initial_state=Hin, dtype=tf.float32)\n",
    "    # Yn[BATCHSIZE, SEQLEN, LSTM_CELLSIZE]\n",
    "    Yn = tf.reshape(Yn, [batchsize*seqlen, LSTM_CELLSIZE])\n",
    "    Yr = tf.layers.dense(Yn, 32) # Yr [BATCHSIZE*SEQLEN, 2]\n",
    "    Yr = tf.reshape(Yr, [batchsize, seqlen, 32]) # Yr [BATCHSIZE, SEQLEN, 2]\n",
    "    Yout = Yr[:,-N_FORWARD:,:] # Last N_FORWARD outputs Yout [BATCHSIZE, N_FORWARD, 2]\n",
    "    \n",
    "    loss = tf.losses.mean_squared_error(Yr, tf.reshape(labels, [1, 1, 32])) # labels[BATCHSIZE, SEQLEN, 2]\n",
    "    \n",
    "    lr = 0.001 + tf.train.exponential_decay(0.01, step, 1000, 0.5)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "    \n",
    "    return Yout, H, loss, train_op, Yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rnn_fn(features, Hin, labels, step, dropout_pkeep):\n",
    "    X = features  # shape [BATCHSIZE, SEQLEN, 2], 2 for (agg_features)\n",
    "    batchsize = tf.shape(X)[0]\n",
    "    seqlen = tf.shape(X)[1]\n",
    "    pairlen = tf.shape(X)[2] # should be 2 (acoustic_data, time_to_failure)?\n",
    "    \n",
    "    cells = [tf.nn.rnn_cell.GRUCell(RNN_CELLSIZE, activation=ACTIVATION) for _ in range(N_LAYERS)]\n",
    "    # dropout useful between cell layers only: no output dropout on last cell\n",
    "    cells = [tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = dropout_pkeep) for cell in cells]\n",
    "    # a stacked RNN cell still works like an RNN cell\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=False)\n",
    "    # X[BATCHSIZE, SEQLEN, 2], Hin[BATCHSIZE, RNN_CELLSIZE*N_LAYERS]\n",
    "    # the sequence unrolling happens here\n",
    "    Yn, H = tf.nn.dynamic_rnn(cell, X, initial_state=Hin, dtype=tf.float32)\n",
    "    # Yn[BATCHSIZE, SEQLEN, RNN_CELLSIZE]\n",
    "    Yn = tf.reshape(Yn, [batchsize*seqlen, RNN_CELLSIZE])\n",
    "    Yr = tf.layers.dense(Yn, 32) # Yr [BATCHSIZE*SEQLEN, 2]\n",
    "    Yr = tf.reshape(Yr, [batchsize, seqlen, 32]) # Yr [BATCHSIZE, SEQLEN, 2]\n",
    "    Yout = Yr[:,-N_FORWARD:,:] # Last N_FORWARD outputs Yout [BATCHSIZE, N_FORWARD, 2]\n",
    "    \n",
    "    loss = tf.losses.mean_squared_error(Yr, tf.reshape(labels, [1, 1, 32])) # labels[BATCHSIZE, SEQLEN, 2]\n",
    "    \n",
    "    lr = 0.001 + tf.train.exponential_decay(0.01, step, 1000, 0.5)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "    \n",
    "    return Yout, H, loss, train_op, Yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # restart model graph from scratch\n",
    "\n",
    "# placeholder for inputs\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    Hin = tf.placeholder(tf.float32, [None, RNN_CELLSIZE * N_LAYERS], name=\"Hin\")\n",
    "    features = tf.placeholder(tf.float32, [None, None, 16], name=\"features\") # [BATCHSIZE, SEQLEN, 2]\n",
    "    labels = tf.placeholder(tf.float32, [32], name=\"labels\") # [BATCHSIZE, SEQLEN, 2]??\n",
    "    step = tf.placeholder(tf.int32, name=\"step\")\n",
    "    dropout_pkeep = tf.placeholder(tf.float32, name=\"dropout_pkeep\")\n",
    "\n",
    "# instantiate the model\n",
    "Yout, H, loss, train_op, Yr = model_rnn_fn(features, Hin, labels, step, dropout_pkeep)\n",
    "\n",
    "\n",
    "SAVEDMODEL = JOB_DIR + \"/ckpt\" + str(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'dropout_pkeep': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: dropout_pkeep = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/device:GPU:0\"]()]]\n\nCaused by op 'dropout_pkeep', defined at:\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-83f587d0bdd7>\", line 9, in <module>\n    dropout_pkeep = tf.placeholder(tf.float32, name=\"dropout_pkeep\")\n  File \"/home/iqiao/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/iqiao/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\n    name=name)\n  File \"/home/iqiao/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/iqiao/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/iqiao/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'dropout_pkeep': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: dropout_pkeep = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1116\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1165\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1166\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'dropout_pkeep': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: dropout_pkeep = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-fdfe12bf7e77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'dropout_pkeep': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: dropout_pkeep = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/device:GPU:0\"]()]]\n\nCaused by op 'dropout_pkeep', defined at:\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/iqiao/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-83f587d0bdd7>\", line 9, in <module>\n    dropout_pkeep = tf.placeholder(tf.float32, name=\"dropout_pkeep\")\n  File \"/home/iqiao/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/iqiao/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\n    name=name)\n  File \"/home/iqiao/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/iqiao/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/iqiao/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'dropout_pkeep': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: dropout_pkeep = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# variable initialization\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run([init])\n",
    "saver = tf.train.Saver(max_to_keep=1)\n",
    "\n",
    "losses = []\n",
    "indices = []\n",
    "last_epoch = 99999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (next_features, next_labels, evalranges, epoch) in enumerate(train_gen):\n",
    "    if epoch == NB_EPOCHS:\n",
    "        print(f\"Epoch {epoch} reached, saving model...\")\n",
    "        break\n",
    "    if epoch != last_epoch:\n",
    "        batchsize = next_features.shape[0]\n",
    "        H_ = np.zeros([batchsize, RNN_CELLSIZE * N_LAYERS])\n",
    "        print(\"State reset on new epoch: %s\"%epoch)\n",
    "    #train\n",
    "    feed = {Hin: H_, features: next_features, labels: next_labels, step: i, dropout_pkeep: DROPOUT_PKEEP}\n",
    "    Yout_, H_, loss_, _, Yr_ = sess.run([Yout, H, loss, train_op, Yr], feed_dict=feed)\n",
    "    \n",
    "    # print progress\n",
    "    if i%20 == 0:\n",
    "        print(\"{}: epoch {} loss = {}\".format(i, epoch, np.mean(loss_)))\n",
    "        sys.stdout.flush()\n",
    "    if i%10 == 0:\n",
    "        losses.append(np.mean(loss_))\n",
    "        indices.append(i)\n",
    "        \n",
    "    last_epoch = epoch\n",
    "saver.save(sess, SAVEDMODEL)\n",
    "#tf.saved_model.simple_save(sess, SAVEDMODEL,\n",
    "#                           inputs={\"features\":features, \"Hin\":Hin, \"dropout_pkeep\":dropout_pkeep},\n",
    "#                           outputs={\"Yout\":Yout, \"H\":H})\n",
    "\n",
    "plt.ylim(ymax=np.amax(losses[1:])) # ignore first value for scaling\n",
    "plt.plot(indices, losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_run(predict_fn, prime_data, run_length):\n",
    "    H = np.zeros([1, RNN_CELLSIZE * N_LAYERS]) # zero state initially\n",
    "    Yout = np.zeros([1, N_FORWARD, 2])\n",
    "    data_len = prime_data.shape[0]-N_FORWARD\n",
    "\n",
    "    # prime the state from data\n",
    "    if data_len > 0:\n",
    "        Yin = np.array(prime_data[:-N_FORWARD])\n",
    "        Yin = np.reshape(Yin, [1, data_len, 2]) # reshape as one sequence of pairs (Tmin, Tmax)\n",
    "        r = predict_fn({'features': Yin, 'Hin':H, 'dropout_pkeep':1.0}) # no dropout during inference\n",
    "        Yout = r[\"Yout\"]\n",
    "        H = r[\"H\"]\n",
    "        \n",
    "        # initaily, put real data on the inputs, not predictions\n",
    "        Yout = np.expand_dims(prime_data[-N_FORWARD:], axis=0)\n",
    "        # Yout shape [1, N_FORWARD, 2]: batch of a single sequence of length N_FORWARD of (Tmin, Tmax) data pointa\n",
    "    \n",
    "    # run prediction\n",
    "    # To generate a sequence, run a trained cell in a loop passing as input and input state\n",
    "    # respectively the output and output state from the previous iteration.\n",
    "    results = []\n",
    "    for i in range(run_length//N_FORWARD+1):\n",
    "        r = predict_fn({'features': Yout, 'Hin':H, 'dropout_pkeep':1.0}) # no dropout during inference\n",
    "        Yout = r[\"Yout\"]\n",
    "        H = r[\"H\"]\n",
    "        results.append(Yout[0]) # shape [N_FORWARD, 2]\n",
    "        \n",
    "    return np.concatenate(results, axis=0)[:run_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKSIZE = 150*100*2\n",
    "#this RESAMPLE_BY is the size of your smoothing kernel? \n",
    "# -don't worry, seems feature extraction took care of this?\n",
    "#worth a try later if training too slow/bad convergence on loss...\n",
    "#sampling rate is 4GHZ???\n",
    "# Try starting predictions from January / March / July (resp. OFFSET = YEAR or YEAR+QYEAR or YEAR+2*QYEAR)\n",
    "# Some start dates are more challenging for the model than others.\n",
    "#OFFSET = 30*YEAR+1*QYEAR\n",
    "OFFSET = 30*CHUNKSIZE#coef of OFFSET upper bounded by 4196/2 - BATCH_LIMIT\n",
    "\n",
    "PRIMELEN=5*CHUNKSIZE#?something extra? CHUNKSIZE was YEAR\n",
    "\n",
    "RUNLEN=BATCH_LIMIT*CHUNKSIZE\n",
    "RMSELEN=3*CHUNKSIZE # accuracy of predictions next 3 chunks???\n",
    "\n",
    "predict_fn = tf.contrib.predictor.from_saved_model(SAVEDMODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for evaldata in valid_gen:\n",
    "    prime_data = evaldata[OFFSET:OFFSET+PRIMELEN]\n",
    "    results = prediction_run(predict_fn, prime_data, RUNLEN)\n",
    "    picture_this(evaldata, evalranges, \n",
    "        prime_data, results, PRIMELEN, RUNLEN, OFFSET, RMSELEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import transforms as plttrans\n",
    "import math\n",
    "def picture_this(evaldata, evalranges, prime_data, results, primelen, runlen, offset, rmselen):\n",
    "    disp_data = evaldata[offset:offset+primelen+runlen]\n",
    "    disp_dates = evalranges[offset:offset+primelen+runlen]\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    displayresults = np.ma.array(np.concatenate((np.zeros([primelen,2]), results)))\n",
    "    displayresults = np.ma.masked_where(displayresults == 0, displayresults)\n",
    "    sp = plt.subplot(212)\n",
    "    p = plt.fill_between(disp_dates, displayresults[:,0], displayresults[:,1])\n",
    "    p.set_alpha(0.8)\n",
    "    p.set_zorder(10)\n",
    "    trans = plttrans.blended_transform_factory(sp.transData, sp.transAxes)\n",
    "    plt.text(disp_dates[primelen],0.05,\"DATA |\", color=colors[1], horizontalalignment=\"right\", transform=trans)\n",
    "    plt.text(disp_dates[primelen],0.05,\"| +PREDICTED\", color=colors[0], horizontalalignment=\"left\", transform=trans)\n",
    "    plt.fill_between(disp_dates, disp_data[:,0], disp_data[:,1])\n",
    "    plt.axvspan(disp_dates[primelen], disp_dates[primelen+rmselen], color='grey', alpha=0.1, ymin=0.05, ymax=0.95)\n",
    "    plt.show()\n",
    "\n",
    "    rmse = math.sqrt(np.mean((evaldata[offset+primelen:offset+primelen+rmselen] - results[:rmselen])**2))\n",
    "    print(\"RMSE on {} predictions (shaded area): {}\".format(rmselen, rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
